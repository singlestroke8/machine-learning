import os
import logging
import pandas as pd
import joblib
import optuna
from optuna.samplers import TPESampler
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from lightgbm import LGBMClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, make_scorer
import json

# Optunaã®ãƒ­ã‚°ãŒå¤šã™ãã‚‹ã®ã§ã€INFOãƒ¬ãƒ™ãƒ«ï¼ˆæœ€é©åŒ–ã®çµæœã®ã¿ï¼‰ã«åˆ¶é™
optuna.logging.set_verbosity(optuna.logging.INFO)
logging.basicConfig(level=logging.INFO, format='%(message)s')

def build_preprocessor(numeric_features: list, categorical_features: list) -> ColumnTransformer:
    """å‰å‡¦ç†å™¨ã®æ§‹ç¯‰ï¼ˆDay 8ã‹ã‚‰å…±é€šã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼‰"""
    return ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), numeric_features),
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)
        ],
        remainder='passthrough'
    )

def save_metrics(metrics: dict, output_path: str) -> None:
    """è©•ä¾¡æŒ‡æ¨™ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã™ã‚‹"""
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(metrics, f, indent=4)
    logging.info(f"è©•ä¾¡æŒ‡æ¨™ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")

def main() -> None:
    input_file = "data/interim/features.csv"
    os.makedirs("models", exist_ok=True)

    try:
        logging.info("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨åˆ†å‰²ã‚’é–‹å§‹ã—ã¾ã™...")
        df = pd.read_csv(input_file)
        target_col = 'Churn'
        X = df.drop(columns=[target_col, 'customerID'])
        y = df[target_col].map({'Yes': 1, 'No': 0})

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿(20%)ã¯å®Œå…¨ã«åˆ‡ã‚Šé›¢ã—ã€ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿(80%)å†…ã§ã®CVã§è¡Œã†
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()
        categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()
        preprocessor = build_preprocessor(numeric_features, categorical_features)

        # Optunaã®ç›®çš„é–¢æ•°ï¼ˆObjective Functionï¼‰ã®å®šç¾©
        def objective(trial):
            # 1. æ¢ç´¢ã™ã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç¯„å›²ã‚’å®šç¾©
            params = {
                'random_state': 42,
                'class_weight': 'balanced', # å¿…é ˆ: ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿å¯¾ç­–
                'verbose': -1,              # LightGBMã®ä¸è¦ãªè­¦å‘Šã‚’æ¶ˆã™
                'n_estimators': trial.suggest_int('n_estimators', 50, 300),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
                'num_leaves': trial.suggest_int('num_leaves', 20, 100),
                'max_depth': trial.suggest_int('max_depth', 3, 10),
                'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),
                'subsample': trial.suggest_float('subsample', 0.6, 1.0),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
            }

            # 2. ææ¡ˆã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½œæˆ
            model = LGBMClassifier(**params)
            pipeline = Pipeline(steps=[
                ('preprocessor', preprocessor),
                ('classifier', model)
            ])

            # 3. 5-Fold CVã§ã€ŒF1-scoreã€ã‚’è¨ˆç®—
            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
            f1_scorer = make_scorer(f1_score)
            scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=f1_scorer, n_jobs=-1)
            
            # 5å›ã®ãƒ†ã‚¹ãƒˆã®å¹³å‡F1ã‚¹ã‚³ã‚¢ã‚’è¿”ã™ï¼ˆã“ã‚Œã‚’æœ€å¤§åŒ–ã™ã‚‹ã‚ˆã†ã«OptunaãŒå‹•ãï¼‰
            return scores.mean()

        logging.info("Optunaã«ã‚ˆã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¢ç´¢ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆ20å›ã®ãƒˆãƒ©ã‚¤ã‚¢ãƒ«ï¼‰...\n" + "="*50)
        
        # ã‚¹ã‚¿ãƒ‡ã‚£ã®ä½œæˆï¼ˆF1ã‚¹ã‚³ã‚¢ã‚’ã€Œæœ€å¤§åŒ–(maximize)ã€ã™ã‚‹æ–¹å‘ã§æ¢ç´¢ï¼‰
        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=42))
        
        # æ¢ç´¢ã®å®Ÿè¡Œï¼ˆæ‰‹å…ƒã®PCã§ã‚‚æ•°åˆ†ã§çµ‚ã‚ã‚‹ã‚ˆã†ã« n_trials=20 ã«è¨­å®šï¼‰
        study.optimize(objective, n_trials=20)

        logging.info("="*50)
        logging.info("ğŸ† ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ï¼")
        logging.info(f"ãƒ™ã‚¹ãƒˆF1ã‚¹ã‚³ã‚¢ (CVå¹³å‡): {study.best_value:.4f}")
        logging.info("ãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
        for key, value in study.best_params.items():
            logging.info(f"  {key}: {value}")

        # --- ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®ãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ ---
        logging.info("\nãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦å…¨å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ãƒ»è©•ä¾¡ã—ã¾ã™...")
        
        best_params = study.best_params
        best_params['random_state'] = 42
        best_params['class_weight'] = 'balanced'
        best_params['verbose'] = -1

        best_model = LGBMClassifier(**best_params)
        best_pipeline = Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('classifier', best_model)
        ])

        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å…¨ä½“ã§Fit
        best_pipeline.fit(X_train, y_train)
        
        # æœªçŸ¥ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æœ€çµ‚è©•ä¾¡
        y_pred = best_pipeline.predict(X_test)
        y_proba = best_pipeline.predict_proba(X_test)[:, 1]

        logging.info("=== æœ€çµ‚ãƒ¢ãƒ‡ãƒ« (Tuned LightGBM) ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿è©•ä¾¡ ===")
        logging.info(f"Accuracy : {accuracy_score(y_test, y_pred):.4f}")
        logging.info(f"Precision: {precision_score(y_test, y_pred):.4f}")
        logging.info(f"Recall   : {recall_score(y_test, y_pred):.4f} (è§£ç´„è€…ã®ç™ºè¦‹ç‡)")
        logging.info(f"F1-score : {f1_score(y_test, y_pred):.4f}")
        logging.info(f"ROC-AUC  : {roc_auc_score(y_test, y_proba):.4f}")
        
        # æŒ‡æ¨™ã‚’è¾æ›¸ï¼ˆã‚­ãƒ¼ã¨å€¤ã®ãƒšã‚¢ï¼‰ã«ã¾ã¨ã‚ã‚‹
        final_metrics = {
            "accuracy": round(acc, 4),
            "precision": round(prec, 4),
            "recall": round(rec, 4),
            "f1_score": round(f1, 4),
            "roc_auc": round(auc, 4)
        }
        
        # reports ãƒ•ã‚©ãƒ«ãƒ€ã« JSON ã¨ã—ã¦ä¿å­˜
        save_metrics(final_metrics, "reports/metrics.json")

        # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
        model_path = "models/tuned_lightgbm_pipeline.pkl"
        joblib.dump(best_pipeline, model_path)
        logging.info(f"\nâœ… ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {model_path}")

    except Exception as e:
        logging.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

if __name__ == "__main__":
    main()