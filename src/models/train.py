import os
import logging
import pandas as pd
import joblib
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import LogisticRegression
# éç·šå½¢ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ
from sklearn.ensemble import RandomForestClassifier
from lightgbm import LGBMClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score


# ãƒ­ã‚®ãƒ³ã‚°ã®è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

def build_pipeline(numeric_features: list, categorical_features: list) -> Pipeline:
    """å‰å‡¦ç†ã¨ãƒ¢ãƒ‡ãƒ«ã‚’çµåˆã—ãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹"""
    
    # 1. å‰å‡¦ç†å™¨ã®å®šç¾© (Day 8ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯)
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), numeric_features),
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)
        ],
        remainder='passthrough'
    )

    # 2. ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®šç¾© (å‰å‡¦ç† -> ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°)
    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', LogisticRegression(random_state=42, max_iter=1000))
    ])
    
    return pipeline

# å‰å‡¦ç†å™¨ã®å®šç¾©ã‚’é–¢æ•°åŒ–ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ«ãƒ¼ãƒ—å†…ã§å†åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
def build_preprocessor(numeric_features: list, categorical_features: list) -> ColumnTransformer:
    return ColumnTransformer(
        transformers=[
            # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ -> æ¨™æº–åŒ– (StandardScaler)
            ('num', StandardScaler(), numeric_features),
            # ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿ -> ãƒ¯ãƒ³ãƒ›ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° (OneHotEncoder)
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)
        ],
        # å‰å‡¦ç†å™¨ã®å¾Œã«æ®‹ã‚‹åˆ—ã¯ãã®ã¾ã¾é€šã™ï¼ˆä»Šå›ã¯customerIDãªã©äºˆæ¸¬ã«ä¸è¦ãªåˆ—ã¯æœ€åˆã‹ã‚‰é™¤å¤–ã—ã¦ã„ã‚‹ã®ã§ã€passthroughã§å•é¡Œãªã„ï¼‰
        remainder='passthrough'
    )

def evaluate_cv(pipeline: Pipeline, X: pd.DataFrame, y: pd.Series, model_name: str) -> dict:
    """ã€ä¿®æ­£ã€‘5-Fold ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚‹å³å¯†ãªè©•ä¾¡ã‚’è¡Œã†"""
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®å‰²åˆï¼ˆè§£ç´„ã®æœ‰ç„¡ï¼‰ã‚’ç¶­æŒã—ãŸã¾ã¾5åˆ†å‰²ã™ã‚‹è¨­å®š
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    
    # è¨ˆç®—ã—ãŸã„è©•ä¾¡æŒ‡æ¨™ã®ãƒªã‚¹ãƒˆ
    scoring = {'acc': 'accuracy', 'prec': 'precision', 'rec': 'recall', 'f1': 'f1', 'auc': 'roc_auc'}
    
    # CVã®å®Ÿè¡Œï¼ˆn_jobs=-1 ã§PCã®å…¨ã‚³ã‚¢ã‚’ä½¿ã£ã¦ä¸¦åˆ—è¨ˆç®—ï¼‰
    cv_results = cross_validate(pipeline, X, y, cv=cv, scoring=scoring, n_jobs=-1)
    
    # 5å›ã®ãƒ†ã‚¹ãƒˆçµæœã®ã€Œå¹³å‡å€¤ã€ã‚’ç®—å‡º
    mean_acc = cv_results['test_acc'].mean()
    mean_prec = cv_results['test_prec'].mean()
    mean_rec = cv_results['test_rec'].mean()
    mean_f1 = cv_results['test_f1'].mean()
    mean_auc = cv_results['test_auc'].mean()
    
    logging.info(f"--- {model_name} (5-Fold CV å¹³å‡) ---")
    logging.info(f"Accuracy : {mean_acc:.4f}")
    logging.info(f"Precision: {mean_prec:.4f}")
    logging.info(f"Recall   : {mean_rec:.4f}")
    logging.info(f"F1-score : {mean_f1:.4f}")
    logging.info(f"ROC-AUC  : {mean_auc:.4f}\n")
    
    return {"acc": mean_acc, "prec": mean_prec, "rec": mean_rec, "f1": mean_f1, "auc": mean_auc}

# è©•ä¾¡ã¨ãƒ­ã‚°å‡ºã—ã‚’è¡Œã†å°‚ç”¨ã®é–¢æ•°
def evaluate_and_log(y_true, y_pred, y_proba, model_name: str) -> dict:
    """è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—ã—ã€ãƒ­ã‚°ã«å‡ºåŠ›ã™ã‚‹"""
    acc = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred)
    rec = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    auc = roc_auc_score(y_true, y_proba)
    
    logging.info(f"--- {model_name} è©•ä¾¡çµæœ ---")
    logging.info(f"Accuracy (æ­£è§£ç‡): {acc:.4f}")
    logging.info(f"Precision(é©åˆç‡): {prec:.4f}")
    logging.info(f"Recall   (å†ç¾ç‡): {rec:.4f}")
    logging.info(f"F1-score (F1å€¤) : {f1:.4f}")
    logging.info(f"ROC-AUC  (AUCå€¤) : {auc:.4f}\n")
    
    return {"acc": acc, "prec": prec, "rec": rec, "f1": f1, "auc": auc}

def main() -> None:
    input_file = "data/interim/features.csv"
    
    os.makedirs("models", exist_ok=True)

    try:
        logging.info(f"ä¸­é–“ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿: {input_file}")
        df = pd.read_csv(input_file)

        # ç‰¹å¾´é‡(X)ã¨ç›®çš„å¤‰æ•°(y)ã«åˆ†å‰²
        target_col = 'Churn'
        X = df.drop(columns=[target_col, 'customerID'])
        y = df[target_col].map({'Yes': 1, 'No': 0})

        # æœ€çµ‚ç¢ºèªç”¨ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆ20%ï¼‰ã‚’åˆ‡ã‚Šé›¢ã™ã€‚CVã¯æ®‹ã‚Šã®80%ï¼ˆX_trainï¼‰ã§è¡Œã†ã€‚
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        logging.info(f"ãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†: Train({X_train.shape[0]}è¡Œ), Test({X_test.shape[0]}è¡Œ)")

        # ã‚«ãƒ©ãƒ ã®å‹ã‚’è‡ªå‹•åˆ¤åˆ¥
        # æ•°å€¤ã‚«ãƒ©ãƒ ã¨ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ã‚«ãƒ©ãƒ ã‚’ãƒªã‚¹ãƒˆåŒ–ã—ã¦ã€å‰å‡¦ç†å™¨ã®å®šç¾©ã«åˆ©ç”¨ã™ã‚‹
        numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()
        # æ–‡å­—åˆ—ã‚«ãƒ©ãƒ ã‚’ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ã‚«ãƒ©ãƒ ã¨ã¿ãªã™ï¼ˆã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯objectå‹ãŒã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ï¼‰
        categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()

        # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã‚’å­¦ç¿’ï¼ˆå†…éƒ¨ã§å‰å‡¦ç†ã®Fitã¨ãƒ¢ãƒ‡ãƒ«ã®FitãŒé †ç•ªã«å®Ÿè¡Œã•ã‚Œã‚‹ï¼‰
        logging.info("ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆå‰å‡¦ç†ï¼‹ãƒ¢ãƒ‡ãƒ«ï¼‰ã®å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...")

        # å‰å‡¦ç†å™¨ã‚’å…ˆã«ä½œæˆã—ã¦ãŠã„ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ«ãƒ¼ãƒ—å†…ã§å†åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
        preprocessor = build_preprocessor(numeric_features, categorical_features)

        # 3ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¾æ›¸ã«è©°ã‚ã¦forãƒ«ãƒ¼ãƒ—ã§å›ã™
        models = {
            "Logistic Regression": LogisticRegression(random_state=42, max_iter=1000),
            # class_weight='balanced' ã‚’ä»˜ã‘ã‚‹ã“ã¨ã§ã€è§£ç´„è€…ã®è¦‹è½ã¨ã—ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’é‡ãã™ã‚‹
            "Random Forest (Balanced)": RandomForestClassifier(random_state=42, n_estimators=100, class_weight='balanced'),
            "LightGBM (Balanced)": LGBMClassifier(random_state=42, class_weight='balanced', verbose=-1)
        }

        # ãƒ«ãƒ¼ãƒ—ã®å¤–ã§ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢ã‚’ä¿æŒã™ã‚‹å¤‰æ•°ã‚’æº–å‚™
        best_auc = 0          # æœ€é«˜AUCã‚¹ã‚³ã‚¢
        best_model_name = ""  # æœ€é«˜ãƒ¢ãƒ‡ãƒ«ã®åå‰
        best_pipeline = None  # æœ€é«˜ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

        logging.info("å„ãƒ¢ãƒ‡ãƒ«ã®ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆCVï¼‰è©•ä¾¡ã‚’é–‹å§‹ã—ã¾ã™ã€‚\n" + "="*45)

        for name, model in models.items():
            pipeline = Pipeline(steps=[
                ('preprocessor', preprocessor),
                ('classifier', model)
            ])

            # ã€ä¿®æ­£ã€‘X_train ã®ä¸­ã§5åˆ†å‰²ã—ã¦è©•ä¾¡ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ãªã—ï¼‰
            metrics = evaluate_cv(pipeline, X_train, y_train, name)
            
            # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®åˆ¤å®šï¼ˆAUCã‚’åŸºæº–ï¼‰
            if metrics["auc"] > best_auc:
                best_auc = metrics["auc"]
                best_model_name = name
                best_pipeline = pipeline

        logging.info("="*45)
        logging.info(f"ğŸ† ãƒãƒ£ãƒ³ãƒ”ã‚ªãƒ³ãƒ¢ãƒ‡ãƒ«: {best_model_name} (CV AUC: {best_auc:.4f})")
        
        # --- æœ€çµ‚è©•ä¾¡ã¨ä¿å­˜ ---
        logging.info("\nãƒãƒ£ãƒ³ãƒ”ã‚ªãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’å…¨å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§å†å­¦ç¿’ã—ã€æœªçŸ¥ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æœ€çµ‚è©•ä¾¡ã—ã¾ã™...")
        best_pipeline.fit(X_train, y_train)
        y_pred = best_pipeline.predict(X_test)
        y_proba = best_pipeline.predict_proba(X_test)[:, 1]
        
        final_auc = roc_auc_score(y_test, y_proba)
        final_rec = recall_score(y_test, y_pred)
        
        logging.info(f"âœ… æœ€çµ‚ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã® AUC: {final_auc:.4f}")
        logging.info(f"âœ… æœ€çµ‚ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã® Recall: {final_rec:.4f} (è§£ç´„è€…ã®ç™ºè¦‹ç‡)")
        
        joblib.dump(best_pipeline, "models/best_model_pipeline.pkl")
        logging.info("\næœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: models/best_model_pipeline.pkl")

    except Exception as e:
        logging.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

if __name__ == "__main__":
    main()